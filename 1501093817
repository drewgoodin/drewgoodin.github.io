<!DOCTYPE HTML>
<html lang='EN-US'>
  <head>
    <meta charset = "UTF-8">
    <title>Drew K Goodin</title>
    <meta name = "viewport" content = "width=device-width">
    <meta name = "viewport" content = "initial-scale=1.0">
    <link rel = "stylesheet"
      type = "text/css"
      href = "/static/style.css" />
  </head>
  <body>
<p>Officially back in the Bay Area. Let's celebrate with a post that combines a few interesting things.</p>

<p>In this post, we will:</p>

<ul>
<li><p>Spin up a few CentOS virtual machines on the command line using <strong><code>virsh</code></strong> and a kickstart file. <a href="#VM">go</a></p></li>
<li><p>Write and run some Ansible playbooks to configure each one as a different component of a site backend (one database and two replica Apache web servers). <a href="#ANS">go</a></p></li>
<li><p>Install and configure an HAProxy load balancer on the host server. <a href="#HAP">go</a></p></li>
<li><p>Use a Perl web client to hit the host server rapidly. <a href="#PWC">go</a></p></li>
<li><p>Collect some metrics from HAProxy. <a href="#MET">go</a></p></li>
</ul>

<p><span id="VM"></span></p>

<h3>VM Provisioning</h3>

<p>We have to take care of a couple of things on the host before creating the guest:</p>

<p>We must create a virtual disk image with the qemu-img utility. This will be attached to the guest upon creation, and the kickstart file will describe how it should be partitioned. This is just a raw 10G image:</p>

<p><code>$ qemu-img create -f raw /var/lib/libvirtd/images/dbase.img 10G</code></p>

<p>Next we need to create a virtual network that provides NAT to the host's wireless interface. <code>virsh</code> and <code>libvirt</code> make this really easy. Virtual networks are defined with an xml file. <code>libvirt</code> provides a default file that we can use as a start. This is found at <code>/usr/share/libvirt/networks/default.xml</code>.</p>

<pre><code>&lt;network&gt;   
  &lt;name&gt;default&lt;/name&gt;   
  &lt;forward mode='nat'&gt;   
    &lt;nat&gt;   
      &lt;port start='1024' end='65535'/&gt;   
    &lt;/nat&gt;   
  &lt;/forward&gt;   
  &lt;bridge name='virbr0' stp='on' delay='0'/&gt;   
  &lt;ip address='192.168.122.1' netmask='255.255.255.0'&gt;   
    &lt;dhcp&gt;   
      &lt;range start='192.168.122.128' end='192.168.100.254'/&gt;   
    &lt;/dhcp&gt;   
  &lt;/ip&gt;   
&lt;/network&gt;   
</code></pre>

<p>We can now use this file to define our virtual network:</p>

<p><code>$ virsh net-define /usr/share/libvirt/networks/default.xml</code></p>

<p>Finally, we need to build a kickstart file. This will completely automate the installation by specifying options that the install process would normally ask us for, including language, location of OS software and package mirrors, and partitioning details. It will also create the root user and password, as well as a normal user "k".</p>

<p>Here is a minimal example. This carves up the 10G image we created in the first step into a 500 MB boot partition and uses the remaining space for an LVM physical volume called pv.01. This physical volume becomes the sole member of a volume group named vg01, which is then separated into three logical volumes: /, /home, and [SWAP].</p>

<pre><code>auth --enableshadow --passalgo=sha512
keyboard --vckeymap=us --xlayouts='us'
lang en_US.UTF-8
text
reboot
network  --bootproto=dhcp --device=eth0 --gateway=192.168.122.1 --ipv6=auto --activate
network  --hostname=web2
rootpw --iscrypted $6$iJB4jrB4ZOBi7UDz$K5/r77NyKW11lxUIHrtVgfEspbSXKUrb9HC14fbMir34JFziGyHj.WnMgbtlw8AuEUvoPbgagfq56/G3CR/vv/
timezone America/Los_Angeles --isUtc --nontp
user --groups=wheel --homedir=/home/k --name=k --password=$6$gsxq4MO0Ixm6bxmG$W7RGyDLgkzGdgAakHqQBgB2Vfj8GRAEhSV11h6R0W1jIexCDDapExb0.90kaetXHbJj397TXy1A54yFwE228s/ --iscrypted --gecos="k"
zerombr
bootloader --location=mbr
clearpart --all --initlabel
part /boot --size 500 --fstype=xfs
part pv.01 --size 9000 
volgroup vg01 pv.01
logvol / --vgname=vg01 --size=3750 --name=centos_root --fstype=xfs
logvol /home --vgname=vg01 --size=1 --grow --maxsize=3000 --name=centos_home --fstype=xfs  
logvol swap --vgname=vg01 --size=1 --grow --name=centos_swap --fstype=xfs
url --url="http://mirror.sjc02.svwh.net/centos/7/os/x86_64/"
repo --name="base" --baseurl="http://mirror.sjc02.svwh.net/centos/7/os/x86_64/"
%packages --nobase --ignoremissing
@core
%end
</code></pre>

<p>Now we just have to build our <code>virt-install</code> command. Per the docs, the minimum required options that need to be specified are  name, memory requirements, guest storage (i.e. disk), and the location of the installation source. We'll add the options for the amount of virtual CPUs, for the virtual network we've created, and for the location of our kickstart file, which will enable completely unattended provisioning.</p>

<p>Here's the complete command. I've placed it in a shell script for reuse. </p>

<pre><code>#!/bin/sh  
virt-install \  
--name=dbase \   
--memory=2048 \  
--vcpus=2 \  
--network network=default \  
--disk path=/var/lib/libvirt/images/dbase.img \   
--location="http://mirror.sjc02.svwh.net/centos/7/os/x86_64/" \  
--extra-args "ks=ftp://usewarnings.com/pub/ks.cfg"  
</code></pre>

<p>Run this with root privileges, and your new CentOS VM should be ready in a few minutes. In this example, we've created the VM to be used for a database (hence its name), with 2 virtual CPUs, 2G RAM and 10G disk space.</p>

<p>The other two will be provisioned similarly, with edits to the guest name and perhaps storage requirements. We'll have to make new disk images with <code>qemu-img create</code> as before. The kickstart file's network directives also need to be modified with the new hostname.</p>

<p><a href="#TOP">top</a></p>

<p><span id="ANS"></span></p>

<h3>Ansible Setup</h3>

<p>Now we have three virtual machines running: <strong>web1</strong>, <strong>web2</strong>, and <strong>dbase</strong>. The host server's <em>/etc/hosts</em> file has been updated so that we can refer to these hostnames on the network.</p>

<p>Let's write an Ansible playbook to install and enable (start on boot) Apache on the web servers, and to install and enable MariaDB on the database server.</p>

<p>First, some preliminaries:</p>

<p>I've made a directory, <em>~/home/ansible-stuff/</em>. In it will be placed our playbooks, a configuration file, and a hosts file. When running <strong><code>ansible-playbook</code></strong> from this directory, Ansible will look first to the configuration file in the current directory, which well let it know that we also have a hosts file present here and to refer to it.</p>

<p><em>ansible.cfg</em>  </p>

<pre><code>[defaults]  
hostfile=hosts  
remote_user=k  
[privilege_escalation]  
become_ask_pass=true
</code></pre>

<p><em>hosts</em></p>

<pre><code>[dbservers]  
dbase

[webservers]  
web[1:2]  
</code></pre>

<p><em>init.yml</em> (this is our playbook)</p>

<pre><code> ---
 - hosts: webservers
   become: true
   tasks:
   - name: install httpd
     yum: name=httpd state=present
   - name: autostart apache
     service: name=httpd enabled=yes

  - hosts: dbservers
    become: true
    tasks:
    - name: install mariadb
      yum: name={{ item  }} state=present
      with_items:
        - mariadb
        - mariadb-server   
    - name: autostart mariadb
      service: name=mariadb enabled=yes
...
</code></pre>

<p>Our playbook is simple and contains two plays (a play is a task or set of tasks for a given host or group). In each play, we set the <code>become</code> directive to true, as we need root privileges to install packages and deal with services. </p>

<p>We can run this playbook with <strong><code>ansible-playbook init.yml</code></strong>. We specified in our config file that Ansible should ask us for a password for sudo purposes, so we are prompted to enter it. For a setup where user prompts are undesirable, we can either change the sudo configuration on the VMs to not require a password for our Ansible user, or we can provide the password with the connection variable <code>ansible_become_pass</code>. This variable can be set in our hosts (also known as inventory) file on a per-host or per group basis, but this is strongly recommended against. Per the docs, a better solution for storing connection variables, especially sensitive ones, is to create directories adjacent to the inventory file with the names <em>group_vars</em> and <em>host_vars</em>. In those directories, we can place files named after groups or hosts, which contain variable assignments in YAML format. See <a href="http://docs.ansible.com/ansible/latest/intro_inventory.html#splitting-out-host-and-group-specific-data">this section</a> of the docs for more info.</p>

<p>We'll now write a playbook to configure Apache on the web servers, and MariaDB on the database server. I'm going to make use of templates, albeit in a very simple way, to demonstrate this feature of Ansible.</p>

<h4>Web Servers</h4>

<p>For the most part, we're going to use Apache's out-of-the-box configuration on <strong>web1</strong> and <strong>web2</strong>. However, we'll use a simple, one-line Jinja2 template to add a configuration file to the /etc/httpd/conf.d/ directory on each server which will provide the proper ServerName directive:</p>

<p><em>~/ansible-stuff/templates/httpd_conf.j2</em></p>

<p><code>ServerName {{ ansible_nodename }}</code></p>

<p>Let's also add a simple Perl script to the default script location on each server. We'll use plain vanilla CGI for this example:</p>

<p><em>~/ansible-stuff/web-scripts/test.pl</em></p>

<pre><code> #!/usr/bin/perl
 use CGI;
 use DBI;
 use strict;
 use warnings;

 my $cgi = CGI-&gt;new();
 my $dbase_info = 'DBI:mysql:database=web_app;host=dbase;port=3306';
 my $db_un = 'k';
 my $db_pw = 'mysql';

 my $dbh = DBI-&gt;connect($dbase_info, $db_un, $db_pw); 
 my @row = $dbh-&gt;selectrow_array('SELECT * FROM test WHERE ID=1');
 my $value = $row[1] . " $row[2]";
 $dbh-&gt;disconnect();

 print $cgi-&gt;header({-type=&gt;'text/plain'});

 my $msg = &lt;&lt;"EOF";
 Congratulations. By accessing this site, you have pulled the following
 name of out the database: $value
 EOF

 print $msg;
</code></pre>

<p>For the script to work, we'll need to make sure the Perl CGI and DBD::mysql modules are installed on the web servers. To install these modules, we should have a cpan client, so we'll install <strong><code>cpanm</code></strong> via <strong><code>yum</code></strong>. Of course, we'll also need to finish setting up the dbase server for the script to execute successfully. That's the next section.</p>

<p>Here is the full playbook for setting up the web servers:</p>

<p><em>~/ansible-stuff/web.yml</em></p>

<pre><code>---
 - hosts: webservers
   become: true
   tasks:  
     - name: add server name to apache configuration
       template: 
         src: ./templates/httpd_conf.j2
         dest: /etc/httpd/conf.d/{{ ansible_nodename }}.conf
       notify: 
       - restart apache
     - name: add a simple script to cgi-bin
       copy:
         src: ./web-scripts/test.pl
         dest: /var/www/cgi-bin/test.pl
         mode: 0755
     - name: install cpan client
       yum: 
         name: perl-App-cpanminus
         state: present
     - name: install CGI and DBD::mysql Perl modules
       cpanm: name={{ item }}
       with_items:
         - CGI
         - DBD::mysql
   handlers:
     - name: restart apache
       service: name=httpd state=restarted
...
</code></pre>

<p>Note that there are some pre-reqs for the DBD::mysql module, namely the gcc compiler and the mysql_config binary; my systems had these already, but if installing DBD::mysql fails for you, consider these two items first.</p>

<h4>Database Server</h4>

<p>The following playbook does a few things:</p>

<ul>
<li><p>Creates a database called "web_app"</p></li>
<li><p>Creates two database users, one for <strong><em>each</em></strong> of our each of our web servers. If we did not include the <code>host</code> attribute, MariaDB would refuse the incoming database connection from the web script.</p></li>
<li><p>Copies a text file containing some SQL statements to create and populate a table for our database</p></li>
<li><p>Restores the web_app database using that text file</p></li>
</ul>

<p>Here it is:</p>

<p><em>~/ansible-stuff/dbase.yml</em></p>

<pre><code>---
 - hosts: dbase
   become: true
   tasks:
     - name: create mariadb database
       mysql_db: 
         name: web_app 
         state: present
     - name: create mariadb user for web1
       mysql_user: 
         name: k
         host: 192.168.122.4
         password: mysql
         priv: 'web_app.*:SELECT'
         state: present
     - name: create mariadb user for web2
       mysql_user: 
         name: k
         host: 192.168.122.121 
         password: mysql
         priv: 'web_app.*:SELECT'
         state: present
     - name: copy database file to host 
       copy: 
         src: ./dbase-files/create.sql
         dest: /tmp
     - name: restore database 
       mysql_db: 
         name: web_app
         state: import
         target: /tmp/create.sql
...
</code></pre>

<p>And here's that text file that we used to populate the database. It's very simple:</p>

<p><em>~/ansible-stuff/dbase-files/create.sql</em></p>

<pre><code>CREATE TABLE test (
ID INT NOT NULL PRIMARY KEY AUTO_INCREMENT,
First VARCHAR(100) NOT NULL,
Last VARCHAR(100) NOT NULL);

INSERT INTO test VALUES(1,'Barry','Lyndon');
</code></pre>

<p>Now if we navigate to the /cgi-bin/test.pl for either one of our web servers in a browser, we get the following output:</p>

<pre><code>Congratulations. By accessing this site, you have pulled the following  
name of out the database: Barry Lyndon
</code></pre>

<p><a href="#TOP">top</a></p>

<p><span id="HAP"></span></p>

<h3>HAProxy Setup</h3>

<p>I am using HAProxy v-1.5.18. There is a <strong><code>yum</code></strong> package available in the CentOS base repo.</p>

<p>All configuration is done via the config file at <em>/etc/haproxy/haproxy.cfg</em></p>

<p>Our setup is painfully simple. I'm using the file as it ships, with some areas commented out and/or slightly modified.</p>

<p>We have the ability to set up content switches so that, for example, HAProxy serves static content from a particular server or group of servers. That's great, but we won't be doing that, for now.</p>

<p>In my file, I didn't touch the "defaults" section. The rest of it is like so:</p>

<pre><code>frontend  main *:80
default_backend  servers

backend servers

    balance  roundrobin 
    server  web1  192.168.122.121:80  check
    server  web2  192.168.122.121:80  check
</code></pre>

<p>For stats collection, make sure the following line is uncommented in the "global" section:</p>

<pre><code>stats socket /var/lib/haproxy/stats
</code></pre>

<p>For logging (on CentOS 7), we have to make some minor changes to <em>/etc/syslog.conf</em>:</p>

<p>The following lines should be added/uncommented:</p>

<pre><code>$ModLoad imudp
$UDPServerRun 514
$AllowedSender UDP, 127.0.0.1
local2.*    /var/log/haproxy.log
</code></pre>

<p>Restart <strong><code>haproxy</code></strong> and <strong><code>rsyslog</code></strong>:</p>

<p><code>sudo systemctl restart haproxy</code> <br />
<code>sudo systemctl restart rsyslog</code></p>

<p>We should also make HAProxy start on boot:</p>

<p><code>sudo systemctl enable haproxy</code></p>

<p>Visiting localhost/cgi-bin/test.pl in the browser presents desired page; success.</p>

<p>Checking the HAProxy logs, we see that web1 and web2 are alternated between:</p>

<p><code>sudo tail -n 2 /var/log/haproxy.log</code>:</p>

<pre><code>Aug  4 11:10:15 localhost haproxy[1578]: 127.0.0.1:37106 [04/Aug/2017:11:10:15.852] main servers/web1 0/0/1/87/88 200 283 - - ---- 1/1/0/1/0 0/0 "GET /cgi-bin/test.pl HTTP/1.1"
Aug  4 11:10:17 localhost haproxy[1578]: 127.0.0.1:37106 [04/Aug/2017:11:10:15.941] main servers/web2 1847/0/1/83/1931 200 283 - - ---- 1/1/0/1/0 0/0 "GET /cgi-bin/test.pl HTTP/1.1"
</code></pre>

<p><a href="#TOP">top</a>
<span id="PWC"></span></p>

<h3>Web Client</h3>

<p>Just to see HAProxy in action, let's run a simple Perl script:</p>

<p>I basically lifted this script from the LWP::Perl module's docs. I just put the request method in a loop, changed the request parameter to reflect the right URI, and changed the output simply to "success" if we get a response:</p>

<pre><code>#!/usr/bin/perl
use strict;
use warnings;
# Create a user agent object
use LWP::UserAgent; 
my $ua = LWP::UserAgent-&gt;new;
$ua-&gt;agent("k's web client");
# Create a request
my $req = HTTP::Request-&gt;new(GET =&gt; 'http://localhost/cgi-bin/test.pl');
# Pass request to the user agent and get a response back
my $res;
for (1 .. 500) {
$res = $ua-&gt;request($req);
# Check the outcome of the response
if ($res-&gt;is_success) {
    print qq?success\n?;
}
else {
    print $res-&gt;status_line, "\n";
}
}
</code></pre>

<p>This will issue an HTTP GET to the load balancer 500 times in quick sequence. In the next section, we'll review what happens.</p>

<p><a href="#TOP">top</a></p>

<p><span id="MET"></span></p>

<h3>HAProxy Stats Collection</h3>

<p>Let's use <strong><code>hatop</code></strong> to take a closer look. This tool mimics <strong><code>top</code></strong> in appearance, but for the HAProxy process specifically.</p>

<p>It's available for download <a href="https://storage.googleapis.com/google-code-archive-downloads/v2/code.google.com/hatop/hatop-0.7.7.tar.gz">here</a></p>

<p>Installation is easy:</p>

<pre><code>tar xf hatop-0.7.7.tar.gz
cd hatop-0.7.7
sudo install -m 755 bin/hatop /usr/local/bin
</code></pre>

<p>We can now run it using the socket file that we made sure to make available in the HAProxy config file:</p>

<pre><code>sudo hatop -s /var/lib/haproxy/stats
</code></pre>

<p>If we navigate to the "Traffic" tab and run our web script, we see it come to life:</p>

<p><img src="http://i.imgur.com/rs4RloS.png" alt="hatop" /></p>

<p><a href="#TOP">top</a></p>
  </body>
</html>
